{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d05f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8e0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca95cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/willfitzhugh/Desktop/Coding/Supply-Chain-Analysis/Data/Interim/Ready_For_Fraud_Featuers.csv')\n",
    "copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ca610f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d43ce577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering to deal with catagorical variables with high cardinality:\n",
    "#flag cities and states with high fraud rate, and those with no recorded fraud\n",
    "#same with product names\n",
    "#cols to engineer: ProductCategory, Customer State, Customer City, ProductDepartment, Order City, Order Country, Order region,\n",
    "#Order state, Product Name\n",
    "\n",
    "#cols to remove: Customer Id, Latitude, Longitude, Order date, Ship date, Order Id, Order status, Customer Name,\n",
    "#order year, real ship days, delivery status, late_delivery_risk, order Status, order year and probably one or more \n",
    "#of [OrderProfit, OrderSales, Order Item Discount, Order Item Discount Rate,Order Item Profit Ratio, product price]\n",
    "\n",
    "#cols to one hot encode: PaymentType, Customer Country, Customer Segment, Market, shipping mode, Order DOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235c6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dums = pd.get_dummies(data[['PaymentType', 'Customer Country', 'Customer Segment', 'Market', 'Shipping Mode',\n",
    "                            'OrderDOW']])\n",
    "\n",
    "data = pd.concat([data,dums], axis=1).drop(columns=['PaymentType', 'Customer Country', 'Customer Segment', 'Market',\n",
    "                                             'Shipping Mode','OrderDOW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afb5ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis mapping strategy/ target encoding in general presents a problem. I may not have data on an order city, so \\nmy model will not be able to handle the order. I could create another model, one that doesn't depend on order city\\nand use that model if the input order has an order city that didn't appear in the train dataset.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have different approach with columns with high cardinality. order city has much higher cardinality than order region\n",
    "#and should be binned differently\n",
    "'''\n",
    "want to keep bins from over fitting to highly cardinal data. I want to avoid marking a city as extremely high risk \n",
    "just because it has one fraud order, and zero non-fraud orders. I still want to mark it has higher risk, but marking\n",
    "it as garaunteed fraud might cause data leakage and over fitting.\n",
    "'''\n",
    "bin_cols = ['ProductCategory', 'Customer State', 'Customer City', 'ProductDepartment', 'Order City', 'Order Country',\n",
    "            'Order Region', 'Order State', 'Product Name']\n",
    "\n",
    "for i in bin_cols: \n",
    "\n",
    "    grouped = data.groupby(i).mean()[['IsFraud']].sort_values('IsFraud', ascending=False).reset_index()\n",
    "    binned = stats.binned_statistic(x = grouped['IsFraud'], values = grouped['IsFraud'], bins = [0, .001, .015, .02, .03, .045, .2, 1])\n",
    "\n",
    "    grouped['bin'] = binned[2]\n",
    "    \n",
    "    bin_map = grouped[[i,'bin']].set_index(i).to_dict()['bin']\n",
    "    \n",
    "    data[i] = data[i].map( bin_map )\n",
    "    \n",
    "    \n",
    "'''\n",
    "This mapping strategy/ target encoding in general presents a problem. I may not have data on an order city, so \n",
    "my model will not be able to handle the order. I could create another model, one that doesn't depend on order city\n",
    "and use that model if the input order has an order city that didn't appear in the train dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0f2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Customer Id','Latitude','Longitude','OrderDate','ShipDate','Order Id','Order Status', \n",
    "                  'CustomerName', 'OrderYear', 'RealShippingDays', 'Delivery Status', 'Late_delivery_risk',\n",
    "                  'Order Status','OrderHour','OrderMonth','Order Item Discount','OrderProfit','Order Item Quantity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e006e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.IsFraud = data.IsFraud.map({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945d30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/willfitzhugh/Desktop/Coding/Supply-Chain-Analysis/Data/Model/FraudData_1.0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
